{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decdbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e846d06",
   "metadata": {},
   "source": [
    "![alt text](dataset.csv_mindmap.png \"Mindmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41883c3e",
   "metadata": {},
   "source": [
    "# Préprocessing\n",
    "| Column name | Column type | Use default transformation ? | Cleaning method | Possible values | Is Label ? |\n",
    "|------|------|------|------|------|------|\n",
    "| Motorway | Nominal Qualitative | Yes | Delete Line | A1 / S52 | No |\n",
    "| SR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| NR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| TR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| VR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| SUR1 | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| SUR2 | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| SUR3 | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| UR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| FR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| OR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| RR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| BR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| MR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| CR | Quantitative Discrete | Yes | Delete Line |  | No |\n",
    "| GreenFrog | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | No |\n",
    "| BrownFrog | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | No |\n",
    "| CommonToad | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | No |\n",
    "| FireBelliedToad | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | No |\n",
    "| TreeFrog | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | No |\n",
    "| CommonNewt | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | No |\n",
    "| greatCreastedNewt | Boolean | Yes | Delete Line | True value = 1 / False value = 0 | Yes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ac662",
   "metadata": {},
   "source": [
    "## We import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ca493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset() -> pd.DataFrame:\n",
    "\tcurrent_dataset = pd.read_csv(\"dataset.csv\", header=1)\n",
    "\tcurrent_dataset.columns = ['Motorway', 'SR', 'NR', 'TR', 'VR', 'SUR1', 'SUR2', 'SUR3', 'UR', 'FR', 'OR', 'RR', 'BR', 'MR', 'CR', 'GreenFrog', 'BrownFrog', 'CommonToad', 'FireBelliedToad', 'TreeFrog', 'CommonNewt', 'greatCreastedNewt']\n",
    "\treturn current_dataset\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "\tdataframe = dataframe.replace(\"?\", np.nan)\n",
    "\tdataframe = dataframe[dataframe[\"Motorway\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"SR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"NR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"TR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"VR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"SUR1\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"SUR2\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"SUR3\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"UR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"FR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"OR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"RR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"BR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"MR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"CR\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"GreenFrog\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"BrownFrog\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"CommonToad\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"FireBelliedToad\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"TreeFrog\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"CommonNewt\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"greatCreastedNewt\"].notna()]\n",
    "\treturn dataframe.reset_index(drop=True)\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "\n",
    "cleaned_dataframe = clean_dataset(dataframe)\n",
    "cleaned_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360e919",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244defb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataframe: pd.DataFrame):\n",
    "\ty = dataframe[\"greatCreastedNewt\"]\n",
    "\tX = dataframe.drop(\"greatCreastedNewt\", axis=1)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\tX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\treturn X_train.reset_index(drop=True), y_train.reset_index(drop=True), X_val.reset_index(drop=True), y_val.reset_index(drop=True), X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "\n",
    "cleaned_dataframe = clean_dataset(dataframe)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(cleaned_dataframe)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5e80f",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(X_train, X_val, X_test):\n",
    "\tone_hot_encoder = OneHotEncoder( categories=[['A1', 'S52']])\n",
    "\tX_train_encoded_values = one_hot_encoder.fit_transform(X_train[[\"Motorway\"]]).toarray()\n",
    "\tX_val_encoded_values = one_hot_encoder.fit_transform(X_val[[\"Motorway\"]]).toarray()\n",
    "\tX_test_encoded_values = one_hot_encoder.fit_transform(X_test[[\"Motorway\"]]).toarray()\n",
    "\n",
    "\n",
    "\tX_train_encoded = pd.DataFrame(X_train_encoded_values, columns=[f\"Motorway_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_val_encoded = pd.DataFrame(X_val_encoded_values, columns=[f\"Motorway_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_test_encoded = pd.DataFrame(X_test_encoded_values, columns=[f\"Motorway_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_train = X_train.join(X_train_encoded)\n",
    "\tX_val = X_val.join(X_val_encoded)\n",
    "\tX_test = X_test.join(X_test_encoded)\n",
    "\n",
    "\tX_train = X_train.drop(\"Motorway\", axis=1)\n",
    "\tX_val = X_val.drop(\"Motorway\", axis=1)\n",
    "\tX_test = X_test.drop(\"Motorway\", axis=1)\n",
    "\tX_train[\"SR\"] = X_train[\"SR\"].astype(float)\n",
    "\tX_val[\"SR\"] = X_val[\"SR\"].astype(float)\n",
    "\tX_test[\"SR\"] = X_test[\"SR\"].astype(float)\n",
    "\tX_train[[\"SR\"]] = minmax_scale(X_train[[\"SR\"]])\n",
    "\tX_val[[\"SR\"]] = minmax_scale(X_val[[\"SR\"]])\n",
    "\tX_test[[\"SR\"]] = minmax_scale(X_test[[\"SR\"]])\n",
    "\n",
    "\tX_train[\"NR\"] = X_train[\"NR\"].astype(float)\n",
    "\tX_val[\"NR\"] = X_val[\"NR\"].astype(float)\n",
    "\tX_test[\"NR\"] = X_test[\"NR\"].astype(float)\n",
    "\tX_train[[\"NR\"]] = minmax_scale(X_train[[\"NR\"]])\n",
    "\tX_val[[\"NR\"]] = minmax_scale(X_val[[\"NR\"]])\n",
    "\tX_test[[\"NR\"]] = minmax_scale(X_test[[\"NR\"]])\n",
    "\n",
    "\tX_train[\"TR\"] = X_train[\"TR\"].astype(float)\n",
    "\tX_val[\"TR\"] = X_val[\"TR\"].astype(float)\n",
    "\tX_test[\"TR\"] = X_test[\"TR\"].astype(float)\n",
    "\tX_train[[\"TR\"]] = minmax_scale(X_train[[\"TR\"]])\n",
    "\tX_val[[\"TR\"]] = minmax_scale(X_val[[\"TR\"]])\n",
    "\tX_test[[\"TR\"]] = minmax_scale(X_test[[\"TR\"]])\n",
    "\n",
    "\tX_train[\"VR\"] = X_train[\"VR\"].astype(float)\n",
    "\tX_val[\"VR\"] = X_val[\"VR\"].astype(float)\n",
    "\tX_test[\"VR\"] = X_test[\"VR\"].astype(float)\n",
    "\tX_train[[\"VR\"]] = minmax_scale(X_train[[\"VR\"]])\n",
    "\tX_val[[\"VR\"]] = minmax_scale(X_val[[\"VR\"]])\n",
    "\tX_test[[\"VR\"]] = minmax_scale(X_test[[\"VR\"]])\n",
    "\n",
    "\tX_train[\"SUR1\"] = X_train[\"SUR1\"].astype(float)\n",
    "\tX_val[\"SUR1\"] = X_val[\"SUR1\"].astype(float)\n",
    "\tX_test[\"SUR1\"] = X_test[\"SUR1\"].astype(float)\n",
    "\tX_train[[\"SUR1\"]] = minmax_scale(X_train[[\"SUR1\"]])\n",
    "\tX_val[[\"SUR1\"]] = minmax_scale(X_val[[\"SUR1\"]])\n",
    "\tX_test[[\"SUR1\"]] = minmax_scale(X_test[[\"SUR1\"]])\n",
    "\n",
    "\tX_train[\"SUR2\"] = X_train[\"SUR2\"].astype(float)\n",
    "\tX_val[\"SUR2\"] = X_val[\"SUR2\"].astype(float)\n",
    "\tX_test[\"SUR2\"] = X_test[\"SUR2\"].astype(float)\n",
    "\tX_train[[\"SUR2\"]] = minmax_scale(X_train[[\"SUR2\"]])\n",
    "\tX_val[[\"SUR2\"]] = minmax_scale(X_val[[\"SUR2\"]])\n",
    "\tX_test[[\"SUR2\"]] = minmax_scale(X_test[[\"SUR2\"]])\n",
    "\n",
    "\tX_train[\"SUR3\"] = X_train[\"SUR3\"].astype(float)\n",
    "\tX_val[\"SUR3\"] = X_val[\"SUR3\"].astype(float)\n",
    "\tX_test[\"SUR3\"] = X_test[\"SUR3\"].astype(float)\n",
    "\tX_train[[\"SUR3\"]] = minmax_scale(X_train[[\"SUR3\"]])\n",
    "\tX_val[[\"SUR3\"]] = minmax_scale(X_val[[\"SUR3\"]])\n",
    "\tX_test[[\"SUR3\"]] = minmax_scale(X_test[[\"SUR3\"]])\n",
    "\n",
    "\tX_train[\"UR\"] = X_train[\"UR\"].astype(float)\n",
    "\tX_val[\"UR\"] = X_val[\"UR\"].astype(float)\n",
    "\tX_test[\"UR\"] = X_test[\"UR\"].astype(float)\n",
    "\tX_train[[\"UR\"]] = minmax_scale(X_train[[\"UR\"]])\n",
    "\tX_val[[\"UR\"]] = minmax_scale(X_val[[\"UR\"]])\n",
    "\tX_test[[\"UR\"]] = minmax_scale(X_test[[\"UR\"]])\n",
    "\n",
    "\tX_train[\"FR\"] = X_train[\"FR\"].astype(float)\n",
    "\tX_val[\"FR\"] = X_val[\"FR\"].astype(float)\n",
    "\tX_test[\"FR\"] = X_test[\"FR\"].astype(float)\n",
    "\tX_train[[\"FR\"]] = minmax_scale(X_train[[\"FR\"]])\n",
    "\tX_val[[\"FR\"]] = minmax_scale(X_val[[\"FR\"]])\n",
    "\tX_test[[\"FR\"]] = minmax_scale(X_test[[\"FR\"]])\n",
    "\n",
    "\tX_train[\"OR\"] = X_train[\"OR\"].astype(float)\n",
    "\tX_val[\"OR\"] = X_val[\"OR\"].astype(float)\n",
    "\tX_test[\"OR\"] = X_test[\"OR\"].astype(float)\n",
    "\tX_train[[\"OR\"]] = minmax_scale(X_train[[\"OR\"]])\n",
    "\tX_val[[\"OR\"]] = minmax_scale(X_val[[\"OR\"]])\n",
    "\tX_test[[\"OR\"]] = minmax_scale(X_test[[\"OR\"]])\n",
    "\n",
    "\tX_train[\"RR\"] = X_train[\"RR\"].astype(float)\n",
    "\tX_val[\"RR\"] = X_val[\"RR\"].astype(float)\n",
    "\tX_test[\"RR\"] = X_test[\"RR\"].astype(float)\n",
    "\tX_train[[\"RR\"]] = minmax_scale(X_train[[\"RR\"]])\n",
    "\tX_val[[\"RR\"]] = minmax_scale(X_val[[\"RR\"]])\n",
    "\tX_test[[\"RR\"]] = minmax_scale(X_test[[\"RR\"]])\n",
    "\n",
    "\tX_train[\"BR\"] = X_train[\"BR\"].astype(float)\n",
    "\tX_val[\"BR\"] = X_val[\"BR\"].astype(float)\n",
    "\tX_test[\"BR\"] = X_test[\"BR\"].astype(float)\n",
    "\tX_train[[\"BR\"]] = minmax_scale(X_train[[\"BR\"]])\n",
    "\tX_val[[\"BR\"]] = minmax_scale(X_val[[\"BR\"]])\n",
    "\tX_test[[\"BR\"]] = minmax_scale(X_test[[\"BR\"]])\n",
    "\n",
    "\tX_train[\"MR\"] = X_train[\"MR\"].astype(float)\n",
    "\tX_val[\"MR\"] = X_val[\"MR\"].astype(float)\n",
    "\tX_test[\"MR\"] = X_test[\"MR\"].astype(float)\n",
    "\tX_train[[\"MR\"]] = minmax_scale(X_train[[\"MR\"]])\n",
    "\tX_val[[\"MR\"]] = minmax_scale(X_val[[\"MR\"]])\n",
    "\tX_test[[\"MR\"]] = minmax_scale(X_test[[\"MR\"]])\n",
    "\n",
    "\tX_train[\"CR\"] = X_train[\"CR\"].astype(float)\n",
    "\tX_val[\"CR\"] = X_val[\"CR\"].astype(float)\n",
    "\tX_test[\"CR\"] = X_test[\"CR\"].astype(float)\n",
    "\tX_train[[\"CR\"]] = minmax_scale(X_train[[\"CR\"]])\n",
    "\tX_val[[\"CR\"]] = minmax_scale(X_val[[\"CR\"]])\n",
    "\tX_test[[\"CR\"]] = minmax_scale(X_test[[\"CR\"]])\n",
    "\n",
    "\tX_train[\"GreenFrog\"] = X_train[\"GreenFrog\"].map({1: True, 0: False})\n",
    "\tX_val[\"GreenFrog\"] = X_val[\"GreenFrog\"].map({1: True, 0: False})\n",
    "\tX_test[\"GreenFrog\"] = X_test[\"GreenFrog\"].map({1: True, 0: False})\n",
    "\n",
    "\tX_train[\"BrownFrog\"] = X_train[\"BrownFrog\"].map({1: True, 0: False})\n",
    "\tX_val[\"BrownFrog\"] = X_val[\"BrownFrog\"].map({1: True, 0: False})\n",
    "\tX_test[\"BrownFrog\"] = X_test[\"BrownFrog\"].map({1: True, 0: False})\n",
    "\n",
    "\tX_train[\"CommonToad\"] = X_train[\"CommonToad\"].map({1: True, 0: False})\n",
    "\tX_val[\"CommonToad\"] = X_val[\"CommonToad\"].map({1: True, 0: False})\n",
    "\tX_test[\"CommonToad\"] = X_test[\"CommonToad\"].map({1: True, 0: False})\n",
    "\n",
    "\tX_train[\"FireBelliedToad\"] = X_train[\"FireBelliedToad\"].map({1: True, 0: False})\n",
    "\tX_val[\"FireBelliedToad\"] = X_val[\"FireBelliedToad\"].map({1: True, 0: False})\n",
    "\tX_test[\"FireBelliedToad\"] = X_test[\"FireBelliedToad\"].map({1: True, 0: False})\n",
    "\n",
    "\tX_train[\"TreeFrog\"] = X_train[\"TreeFrog\"].map({1: True, 0: False})\n",
    "\tX_val[\"TreeFrog\"] = X_val[\"TreeFrog\"].map({1: True, 0: False})\n",
    "\tX_test[\"TreeFrog\"] = X_test[\"TreeFrog\"].map({1: True, 0: False})\n",
    "\n",
    "\tX_train[\"CommonNewt\"] = X_train[\"CommonNewt\"].map({1: True, 0: False})\n",
    "\tX_val[\"CommonNewt\"] = X_val[\"CommonNewt\"].map({1: True, 0: False})\n",
    "\tX_test[\"CommonNewt\"] = X_test[\"CommonNewt\"].map({1: True, 0: False})\n",
    "\n",
    "\treturn X_train, X_val, X_test\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "cleaned_dataframe = clean_dataset(dataframe)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(cleaned_dataframe)\n",
    "X_train, X_val, X_test = transform_data(X_train, X_val, X_test)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff8f51",
   "metadata": {},
   "source": [
    "# Mining\n",
    "| Classifier type | Hyper-parameters | Grid name |\n",
    "|------|------|------|\n",
    "| svc_classifier | {'C': [1.0, 2.0]} | grid_search_svc_classifier |\n",
    "| decision_tree_classifier | {'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy'], 'min_samples_split': [10, 12]} | grid_search_decision_tree_classifier |\n",
    "| k_neighbor_classifier | {'n_neighbors': [5, 8]} | grid_search_k_neighbor_classifier |\n",
    "| mlp_classifier | {'solver': ['sgd', 'adam'], 'activation': ['tanh', 'identity']} | grid_search_mlp_classifier |\n",
    "| random_forest_classifier | {'criterion': ['gini', 'entropy'], 'n_estimators': [5, 2, 7]} | grid_search_random_forest_classifier |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_svc_classifier = GridSearchCV(estimator=svc_classifier, param_grid={'C': [1.0, 2.0]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_svc_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_svc_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd128f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_decision_tree_classifier = GridSearchCV(estimator=decision_tree_classifier, param_grid={'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy'], 'min_samples_split': [10, 12]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_decision_tree_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_decision_tree_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbor_classifier = KNeighborsClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_k_neighbor_classifier = GridSearchCV(estimator=k_neighbor_classifier, param_grid={'n_neighbors': [5, 8]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_k_neighbor_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_k_neighbor_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a50e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_mlp_classifier = GridSearchCV(estimator=mlp_classifier, param_grid={'solver': ['sgd', 'adam'], 'activation': ['tanh', 'identity']}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_mlp_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_mlp_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d78fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_random_forest_classifier = GridSearchCV(estimator=random_forest_classifier, param_grid={'criterion': ['gini', 'entropy'], 'n_estimators': [5, 2, 7]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_random_forest_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_random_forest_classifier.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaac29a",
   "metadata": {},
   "source": [
    "# Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparaison_chart(grid_search_name):\n",
    "\tresults = grid_search_name.cv_results_\n",
    "\tparams = results[\"params\"]\n",
    "\tmean_tst_scores = results[\"mean_test_score\"]\n",
    "\tfor index, p in enumerate(params):\n",
    "\t\tp[\"mean_test_score\"] = mean_tst_scores[index]\n",
    "\tresults_dataframe = pd.DataFrame(params)\n",
    "\n",
    "\tcolumns_name = results_dataframe.columns.to_list()\n",
    "\tresults_dataframe = results_dataframe.sort_values(by=[\"mean_test_score\"], ascending=False)\n",
    "\tcolumns_name.remove(\"mean_test_score\")\n",
    "\tresults_dataframe[\"combinaison_hyperparameters\"] = results_dataframe[columns_name].apply(lambda x: \" | \".join(map(str, x)), axis=1)\n",
    "\n",
    "\n",
    "\tplt.barh(results_dataframe[\"combinaison_hyperparameters\"], results_dataframe[\"mean_test_score\"])\n",
    "\tplt.xlabel = \"score\"\n",
    "\tplt.ylabel = \"combinaison de paramètres\"\n",
    "\tplt.title = \"Résultats d entrainement\"\n",
    "\tplt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8defa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_chart(grid_search_svc_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_chart(grid_search_decision_tree_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ccfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_chart(grid_search_k_neighbor_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "y_test_format = y_test.to_numpy()\n",
    "y_test_format = np.array(np.where(y_test_format == \"no\", 0, 1), dtype=int)\n",
    "prediction = grid_search_svc_classifier.predict(X_test)\n",
    "prediction = np.array(np.where(prediction == \"no\", 0, 1), dtype=int)\n",
    "scores[\"svc_classifier\"] = {}\n",
    "\n",
    "scores[\"svc_classifier\"][\"precision\"] = precision_score(y_test_format, prediction)\n",
    "\n",
    "scores[\"svc_classifier\"][\"recall\"] = recall_score(y_test_format, prediction)\n",
    "\n",
    "prediction = grid_search_k_neighbor_classifier.predict(X_test)\n",
    "prediction = np.array(np.where(prediction == \"no\", 0, 1), dtype=int)\n",
    "scores[\"k_neighbor_classifier\"] = {}\n",
    "\n",
    "scores[\"k_neighbor_classifier\"][\"precision\"] = precision_score(y_test_format, prediction)\n",
    "\n",
    "scores[\"k_neighbor_classifier\"][\"recall\"] = recall_score(y_test_format, prediction)\n",
    "\n",
    "prediction = grid_search_decision_tree_classifier.predict(X_test)\n",
    "prediction = np.array(np.where(prediction == \"no\", 0, 1), dtype=int)\n",
    "scores[\"decision_tree_classifier\"] = {}\n",
    "\n",
    "scores[\"decision_tree_classifier\"][\"precision\"] = precision_score(y_test_format, prediction)\n",
    "\n",
    "scores[\"decision_tree_classifier\"][\"recall\"] = recall_score(y_test_format, prediction)\n",
    "\n",
    "plot_df = pd.DataFrame(scores)\n",
    "for cls in ['svc_classifier', 'k_neighbor_classifier', 'decision_tree_classifier']:\n",
    "\tplot_df.plot(y=cls, kind=\"bar\", use_index=True)\n",
    "plot_df\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
