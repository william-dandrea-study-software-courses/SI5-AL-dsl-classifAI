{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c97c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b080f",
   "metadata": {},
   "source": [
    "![alt text](dataset.csv_mindmap.png \"Mindmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f86e66",
   "metadata": {},
   "source": [
    "# Préprocessing\n",
    "| Column name | Column type | Use default transformation ? | Cleaning method | Possible values | Is Label ? |\n",
    "|------|------|------|------|------|------|\n",
    "| color | Nominal Qualitative | Yes | Delete Line | YELLOW / PURPLE | No |\n",
    "| size | Ordinal Qualitative | Yes | Delete Line | SMALL / LARGE | No |\n",
    "| act | Nominal Qualitative | Yes | Delete Line | STRETCH / DIP | No |\n",
    "| age | Nominal Qualitative | Yes | Delete Line | ADULT / CHILD | No |\n",
    "| result | Boolean | Yes | Delete Line | True value = T / False value = F | Yes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e24b9b",
   "metadata": {},
   "source": [
    "## We import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset() -> pd.DataFrame: \n",
    "\tcurrent_dataset = pd.read_csv(\"dataset.csv\", header=None) \n",
    "\tcurrent_dataset.columns = ['color', 'size', 'act', 'age', 'result'] \n",
    "\treturn current_dataset \n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset() \n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec536df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "\tdataframe = dataframe.replace(\"?\", np.nan)\n",
    "\tdataframe = dataframe[dataframe[\"color\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"size\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"act\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"age\"].notna()]\n",
    "\tdataframe = dataframe[dataframe[\"result\"].notna()]\n",
    "\treturn dataframe.reset_index(drop=True)\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "\n",
    "cleaned_dataframe = clean_dataset(dataframe)\n",
    "cleaned_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a489818",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataframe: pd.DataFrame):\n",
    "\ty = dataframe[\"result\"]\n",
    "\tX = dataframe.drop(\"result\", axis=1)\n",
    "\t\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\t\n",
    "\tX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\t\n",
    "\treturn X_train.reset_index(drop=True), y_train.reset_index(drop=True), X_val.reset_index(drop=True), y_val.reset_index(drop=True), X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "\n",
    "cleaned_dataframe = clean_dataset(dataframe)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(cleaned_dataframe)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd60b16",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(X_train, X_val, X_test):\n",
    "\tone_hot_encoder = OneHotEncoder( categories=[['YELLOW', 'PURPLE']])\n",
    "\tX_train_encoded_values = one_hot_encoder.fit_transform(X_train[[\"color\"]]).toarray()\n",
    "\tX_val_encoded_values = one_hot_encoder.fit_transform(X_val[[\"color\"]]).toarray()\n",
    "\tX_test_encoded_values = one_hot_encoder.fit_transform(X_test[[\"color\"]]).toarray()\n",
    "\t\n",
    "\t\n",
    "\tX_train_encoded = pd.DataFrame(X_train_encoded_values, columns=[f\"color_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_val_encoded = pd.DataFrame(X_val_encoded_values, columns=[f\"color_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_test_encoded = pd.DataFrame(X_test_encoded_values, columns=[f\"color_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_train = X_train.join(X_train_encoded)\n",
    "\tX_val = X_val.join(X_val_encoded)\n",
    "\tX_test = X_test.join(X_test_encoded)\n",
    "\t\n",
    "\tX_train = X_train.drop(\"color\", axis=1)\n",
    "\tX_val = X_val.drop(\"color\", axis=1)\n",
    "\tX_test = X_test.drop(\"color\", axis=1)\n",
    "\tordinal_encoder = OrdinalEncoder(categories=[['SMALL', 'LARGE']])\n",
    "\tX_train[\"size\"] = ordinal_encoder.fit_transform(X_train[[\"size\"]])\n",
    "\tX_val[\"size\"] = ordinal_encoder.fit_transform(X_val[[\"size\"]])\n",
    "\tX_test[\"size\"] = ordinal_encoder.fit_transform(X_test[[\"size\"]])\n",
    "\t\n",
    "\tone_hot_encoder = OneHotEncoder( categories=[['STRETCH', 'DIP']])\n",
    "\tX_train_encoded_values = one_hot_encoder.fit_transform(X_train[[\"act\"]]).toarray()\n",
    "\tX_val_encoded_values = one_hot_encoder.fit_transform(X_val[[\"act\"]]).toarray()\n",
    "\tX_test_encoded_values = one_hot_encoder.fit_transform(X_test[[\"act\"]]).toarray()\n",
    "\t\n",
    "\t\n",
    "\tX_train_encoded = pd.DataFrame(X_train_encoded_values, columns=[f\"act_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_val_encoded = pd.DataFrame(X_val_encoded_values, columns=[f\"act_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_test_encoded = pd.DataFrame(X_test_encoded_values, columns=[f\"act_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_train = X_train.join(X_train_encoded)\n",
    "\tX_val = X_val.join(X_val_encoded)\n",
    "\tX_test = X_test.join(X_test_encoded)\n",
    "\t\n",
    "\tX_train = X_train.drop(\"act\", axis=1)\n",
    "\tX_val = X_val.drop(\"act\", axis=1)\n",
    "\tX_test = X_test.drop(\"act\", axis=1)\n",
    "\tone_hot_encoder = OneHotEncoder( categories=[['ADULT', 'CHILD']])\n",
    "\tX_train_encoded_values = one_hot_encoder.fit_transform(X_train[[\"age\"]]).toarray()\n",
    "\tX_val_encoded_values = one_hot_encoder.fit_transform(X_val[[\"age\"]]).toarray()\n",
    "\tX_test_encoded_values = one_hot_encoder.fit_transform(X_test[[\"age\"]]).toarray()\n",
    "\t\n",
    "\t\n",
    "\tX_train_encoded = pd.DataFrame(X_train_encoded_values, columns=[f\"age_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_val_encoded = pd.DataFrame(X_val_encoded_values, columns=[f\"age_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_test_encoded = pd.DataFrame(X_test_encoded_values, columns=[f\"age_{x}\" for x in one_hot_encoder.categories_[0]])\n",
    "\tX_train = X_train.join(X_train_encoded)\n",
    "\tX_val = X_val.join(X_val_encoded)\n",
    "\tX_test = X_test.join(X_test_encoded)\n",
    "\t\n",
    "\tX_train = X_train.drop(\"age\", axis=1)\n",
    "\tX_val = X_val.drop(\"age\", axis=1)\n",
    "\tX_test = X_test.drop(\"age\", axis=1)\n",
    "\treturn X_train, X_val, X_test\n",
    "\n",
    "dataframe: pd.DataFrame = load_dataset()\n",
    "cleaned_dataframe = clean_dataset(dataframe)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(cleaned_dataframe)\n",
    "X_train, X_val, X_test = transform_data(X_train, X_val, X_test)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65827214",
   "metadata": {},
   "source": [
    "# Mining \n",
    "| Classifier type | Hyper-parameters | Grid name |\n",
    "|------|------|------|\n",
    "| svc_classifier | {'C': [1.0, 2.0]} | grid_search_svc_classifier |\n",
    "| decision_tree_classifier | {'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy'], 'min_samples_split': [10, 12]} | grid_search_decision_tree_classifier |\n",
    "| k_neighbor_classifier | {'n_neighbors': [5, 8]} | grid_search_k_neighbor_classifier |\n",
    "| mlp_classifier | {'solver': ['sgd', 'adam'], 'activation': ['tanh', 'identity']} | grid_search_mlp_classifier |\n",
    "| random_forest_classifier | {'criterion': ['gini', 'entropy'], 'n_estimators': [5, 2, 7]} | grid_search_random_forest_classifier |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93995a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_svc_classifier = GridSearchCV(estimator=svc_classifier, param_grid={'C': [1.0, 2.0]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_svc_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_svc_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_decision_tree_classifier = GridSearchCV(estimator=decision_tree_classifier, param_grid={'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy'], 'min_samples_split': [10, 12]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_decision_tree_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_decision_tree_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbor_classifier = KNeighborsClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_k_neighbor_classifier = GridSearchCV(estimator=k_neighbor_classifier, param_grid={'n_neighbors': [5, 8]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_k_neighbor_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_k_neighbor_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbe3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_mlp_classifier = GridSearchCV(estimator=mlp_classifier, param_grid={'solver': ['sgd', 'adam'], 'activation': ['tanh', 'identity']}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_mlp_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_mlp_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67063fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier()\n",
    "\n",
    "split = [-1 if i < len(X_train) else 0 for i in range(X_train.shape[0] + X_val.shape[0])]\n",
    "grid_search_random_forest_classifier = GridSearchCV(estimator=random_forest_classifier, param_grid={'criterion': ['gini', 'entropy'], 'n_estimators': [5, 2, 7]}, scoring=\"accuracy\", cv=PredefinedSplit(split), verbose=2)\n",
    "grid_search_random_forest_classifier.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "grid_search_random_forest_classifier.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043adfc",
   "metadata": {},
   "source": [
    "# Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparaison_chart(grid_search_name):\n",
    "\tresults = grid_search_name.cv_results_\n",
    "\tparams = results[\"params\"]\n",
    "\tmean_tst_scores = results[\"mean_test_score\"]\n",
    "\tfor index, p in enumerate(params):\n",
    "\t\tp[\"mean_test_score\"] = mean_tst_scores[index]\n",
    "\tresults_dataframe = pd.DataFrame(params)\n",
    "\t\n",
    "\tcolumns_name = results_dataframe.columns.to_list()\n",
    "\tresults_dataframe = results_dataframe.sort_values(by=[\"mean_test_score\"], ascending=False)\n",
    "\tcolumns_name.remove(\"mean_test_score\")\n",
    "\tresults_dataframe[\"combinaison_hyperparameters\"] = results_dataframe[columns_name].apply(lambda x: \" | \".join(map(str, x)), axis=1)\n",
    "\t\n",
    "\t\n",
    "\tplt.barh(results_dataframe[\"combinaison_hyperparameters\"], results_dataframe[\"mean_test_score\"])\n",
    "\tplt.xlabel = \"score\"\n",
    "\tplt.ylabel = \"combinaison de paramètres\"\n",
    "\tplt.title = \"Résultats d entrainement\"\n",
    "\tplt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_chart(grid_search_svc_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83320b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_chart(grid_search_decision_tree_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_chart(grid_search_k_neighbor_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd60410",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "y_test_format = y_test.to_numpy()\n",
    "y_test_format = np.array(np.where(y_test_format == \"no\", 0, 1), dtype=int)\n",
    "prediction = grid_search_svc_classifier.predict(X_test)\n",
    "prediction = np.array(np.where(prediction == \"no\", 0, 1), dtype=int)\n",
    "scores[\"svc_classifier\"] = {}\n",
    "\n",
    "scores[\"svc_classifier\"][\"f1_score\"] = f1_score(y_test_format, prediction)\n",
    "\n",
    "prediction = grid_search_k_neighbor_classifier.predict(X_test)\n",
    "prediction = np.array(np.where(prediction == \"no\", 0, 1), dtype=int)\n",
    "scores[\"k_neighbor_classifier\"] = {}\n",
    "\n",
    "scores[\"k_neighbor_classifier\"][\"f1_score\"] = f1_score(y_test_format, prediction)\n",
    "\n",
    "prediction = grid_search_decision_tree_classifier.predict(X_test)\n",
    "prediction = np.array(np.where(prediction == \"no\", 0, 1), dtype=int)\n",
    "scores[\"decision_tree_classifier\"] = {}\n",
    "\n",
    "scores[\"decision_tree_classifier\"][\"f1_score\"] = f1_score(y_test_format, prediction)\n",
    "\n",
    "plot_df = pd.DataFrame(scores)\n",
    "for cls in ['svc_classifier', 'k_neighbor_classifier', 'decision_tree_classifier']:\n",
    "\tplot_df.plot(y=cls, kind=\"bar\", use_index=True)\n",
    "plot_df\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
